ğŸš€ OpenMP Performance EvaluationUCS645: Parallel and Distributed Computing | Lab Assignment 2This repository contains a performance analysis of three distinct computational problems parallelized using OpenMP. The goal is to evaluate scalability, speedup, and efficiency across varying thread counts on a multi-core architecture.ğŸ›  Experimental SetupLanguage: C/C++ with OpenMP APIMetrics: * Speedup ($S$): $T_{serial} / T_{parallel}$Efficiency ($E$): $S / \text{number of threads}$Hardware Environment: Analyzed on a quad-core physical environment (performance drops observed at 8 threads due to oversubscription).ğŸ§ª Experiment 1: Molecular Dynamics (Lennard-Jones)Objective: Compute pairwise forces and potential energy for a 3D particle system.ğŸ§¬ Implementation StrategyParallelism: Outer loop distribution.Synchronization: atomic updates for force vectors to prevent race conditions.Reduction: Total energy aggregated using the reduction(+:energy) clause.Scheduling: dynamic to mitigate load imbalance in particle interactions.ğŸ“Š Performance MetricsThreadsExecution Time (s)Speedup (S)Efficiency (E)10.10391.00x100%20.05391.93x96.4%40.02713.84x96.0%80.02763.77x47.1%ğŸ§¬ Experiment 2: Smithâ€“Waterman DNA AlignmentObjective: Local sequence alignment using dynamic programming on a $10,000 \times 10,000$ matrix.ğŸ§© The Challenge: Data DependencyUnlike the other experiments, this uses Wavefront (Anti-diagonal) Parallelization. Each cell $H(i, j)$ depends on its top, left, and diagonal neighbors.ğŸ“Š Performance MetricsThreadsExecution Time (s)Speedup (S)Efficiency (E)16.92471.00x100%24.03751.71x85.7%42.74812.51x62.9%87.64400.90x11.3%Critical Note: Performance severely degrades at 8 threads. The synchronization overhead after each diagonal computation outweighs the computational gains when threads exceed physical cores.ğŸŒ¡ï¸ Experiment 3: 2D Heat DiffusionObjective: Simulate heat transfer across a $2000 \times 2000$ grid over 500 time steps.ğŸ”¥ Implementation HighlightsDomain Decomposition: Grid points distributed across threads.Efficiency: No race conditions during write-back as threads access distinct memory segments.Cache Bonus: Observed Superlinear Speedup ($E > 1.0$) at 2 and 4 threads, likely due to the sub-problems fitting entirely into the L3 cache.ğŸ“Š Performance MetricsThreadsExecution Time (s)Speedup (S)Efficiency (E)138.35171.00x100%216.96982.26x112.9%49.27614.13x103.3%89.43824.06x50.7%ğŸ Summary of FindingsApplicationBest ScalabilityPrimary BottleneckMolecular DynamicsHighAtomic operation contentionSmith-WatermanLowData dependency & Sync barriersHeat DiffusionExceptionalMemory bandwidth (at high thread counts)ğŸ’¡ ConclusionThe experiment confirms that parallelism is not a free lunch. While Heat Diffusion benefits from cache locality, the strict dependencies in Smith-Waterman prove that synchronization overhead can actually make a program slower than its serial counterpart when oversubscribed.
